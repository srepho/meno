"""Supervised topic modeling modules."""

from typing import List, Dict, Optional, Union, Tuple, Any
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity


class TopicMatcher:
    """Class for matching documents to predefined topics.
    
    This class provides methods for matching document embeddings to predefined
    topic embeddings using similarity measures.
    
    Parameters
    ----------
    threshold : float, optional
        Minimum similarity threshold for topic assignment, by default 0.6
    assign_multiple : bool, optional
        Whether to assign multiple topics to a document, by default False
    max_topics_per_doc : int, optional
        Maximum number of topics to assign per document, by default 3
    
    Attributes
    ----------
    threshold : float
        Minimum similarity threshold for topic assignment
    assign_multiple : bool
        Whether to assign multiple topics to a document
    max_topics_per_doc : int
        Maximum number of topics to assign per document
    """
    
    def __init__(
        self,
        threshold: float = 0.6,
        assign_multiple: bool = False,
        max_topics_per_doc: int = 3,
    ):
        """Initialize the topic matcher with specified options."""
        self.threshold = threshold
        self.assign_multiple = assign_multiple
        self.max_topics_per_doc = max_topics_per_doc
    
    def match(
        self,
        document_embeddings: np.ndarray,
        topic_embeddings: np.ndarray,
        topic_names: List[str],
    ) -> pd.DataFrame:
        """Match documents to topics based on embedding similarity.
        
        Parameters
        ----------
        document_embeddings : np.ndarray
            Document embeddings with shape (n_documents, embedding_dim)
        topic_embeddings : np.ndarray
            Topic embeddings with shape (n_topics, embedding_dim)
        topic_names : List[str]
            Names of the topics
        
        Returns
        -------
        pd.DataFrame
            DataFrame with topic assignments and similarity scores
        
        Raises
        ------
        ValueError
            If inputs have invalid shapes or lengths
        """
        # Validate inputs
        if document_embeddings.shape[1] != topic_embeddings.shape[1]:
            raise ValueError(
                f"Embedding dimensions do not match: "
                f"{document_embeddings.shape[1]} vs {topic_embeddings.shape[1]}"
            )
        
        if len(topic_names) != topic_embeddings.shape[0]:
            raise ValueError(
                f"Number of topic names ({len(topic_names)}) does not match "
                f"number of topic embeddings ({topic_embeddings.shape[0]})"
            )
        
        # Calculate similarity between documents and topics
        similarity = cosine_similarity(document_embeddings, topic_embeddings)
        
        # Assign topics based on similarity
        if self.assign_multiple:
            return self._assign_multiple_topics(similarity, topic_names)
        else:
            return self._assign_single_topic(similarity, topic_names)
    
    def _assign_single_topic(
        self,
        similarity: np.ndarray,
        topic_names: List[str],
    ) -> pd.DataFrame:
        """Assign a single topic to each document.
        
        Parameters
        ----------
        similarity : np.ndarray
            Similarity matrix with shape (n_documents, n_topics)
        topic_names : List[str]
            Names of the topics
        
        Returns
        -------
        pd.DataFrame
            DataFrame with topic assignments and similarity scores
        """
        # Find the most similar topic for each document
        best_topic_idx = np.argmax(similarity, axis=1)
        best_topic_score = np.max(similarity, axis=1)
        
        # Create result DataFrame
        result = pd.DataFrame({
            "primary_topic": [
                topic_names[idx] if score >= self.threshold else "Unknown"
                for idx, score in zip(best_topic_idx, best_topic_score)
            ],
            "topic_probability": best_topic_score,
        })
        
        # Add individual topic similarities
        for i, topic in enumerate(topic_names):
            result[f"{topic}_similarity"] = similarity[:, i]
        
        return result
    
    def _assign_multiple_topics(
        self,
        similarity: np.ndarray,
        topic_names: List[str],
    ) -> pd.DataFrame:
        """Assign multiple topics to each document.
        
        Parameters
        ----------
        similarity : np.ndarray
            Similarity matrix with shape (n_documents, n_topics)
        topic_names : List[str]
            Names of the topics
        
        Returns
        -------
        pd.DataFrame
            DataFrame with topic assignments and similarity scores
        """
        # Initialize result DataFrame
        result = pd.DataFrame()
        
        # For each document, find topics above threshold
        for doc_idx in range(similarity.shape[0]):
            doc_similarity = similarity[doc_idx]
            
            # Sort topics by similarity
            sorted_idx = np.argsort(doc_similarity)[::-1]
            
            # Get topics above threshold, up to max_topics_per_doc
            topics = []
            scores = []
            for idx in sorted_idx[:self.max_topics_per_doc]:
                score = doc_similarity[idx]
                if score >= self.threshold:
                    topics.append(topic_names[idx])
                    scores.append(score)
            
            # If no topics above threshold, assign "Unknown"
            if not topics:
                topics = ["Unknown"]
                scores = [0.0]
            
            # Create a row for this document
            doc_result = pd.DataFrame({
                "primary_topic": [topics[0]],
                "topic_probability": [scores[0]],
                "all_topics": [topics],
                "all_scores": [scores],
            })
            
            # Add individual topic similarities
            for i, topic in enumerate(topic_names):
                doc_result[f"{topic}_similarity"] = doc_similarity[i]
            
            # Append to result
            result = pd.concat([result, doc_result], ignore_index=True)
        
        return result


class TopicClassifier:
    """Class for classifying documents into predefined topics using ML models.
    
    This class provides methods for training classifiers on labeled data to
    predict topic assignments for new documents.
    
    Parameters
    ----------
    model_type : str, optional
        Type of classification model to use, by default "svm"
        Options: "svm", "logistic", "random_forest", "xgboost"
    threshold : float, optional
        Minimum probability threshold for topic assignment, by default 0.3
    
    Attributes
    ----------
    model_type : str
        Type of classification model
    threshold : float
        Minimum probability threshold for topic assignment
    model : Any
        Trained classification model
    topic_names : List[str]
        Names of the topics
    """
    
    def __init__(
        self,
        model_type: str = "svm",
        threshold: float = 0.3,
    ):
        """Initialize the topic classifier with specified options."""
        self.model_type = model_type.lower()
        self.threshold = threshold
        self.model = None
        self.topic_names = None
    
    def _create_model(self) -> Any:
        """Create the appropriate classification model.
        
        Returns
        -------
        Any
            Classification model instance
        
        Raises
        ------
        ValueError
            If model_type is invalid
        """
        if self.model_type == "svm":
            from sklearn.svm import SVC
            return SVC(probability=True, random_state=42)
        elif self.model_type == "logistic":
            from sklearn.linear_model import LogisticRegression
            return LogisticRegression(random_state=42, max_iter=1000)
        elif self.model_type == "random_forest":
            from sklearn.ensemble import RandomForestClassifier
            return RandomForestClassifier(random_state=42)
        elif self.model_type == "xgboost":
            try:
                import xgboost as xgb
                return xgb.XGBClassifier(random_state=42)
            except ImportError:
                raise ValueError(
                    "XGBoost is not installed. "
                    "Install it with: pip install xgboost"
                )
        else:
            raise ValueError(
                f"Invalid model_type: {self.model_type}. "
                f"Must be one of: svm, logistic, random_forest, xgboost"
            )
    
    def fit(
        self,
        embeddings: np.ndarray,
        topics: Union[List[str], pd.Series],
    ) -> "TopicClassifier":
        """Train the classifier on embeddings with known topic labels.
        
        Parameters
        ----------
        embeddings : np.ndarray
            Document embeddings with shape (n_documents, embedding_dim)
        topics : Union[List[str], pd.Series]
            Topic labels for each document
        
        Returns
        -------
        TopicClassifier
            Trained classifier instance
        """
        # Convert pandas Series to list if needed
        if isinstance(topics, pd.Series):
            topics = topics.tolist()
        
        # Get unique topic names
        self.topic_names = sorted(list(set(topics)))
        
        # Create and train model
        self.model = self._create_model()
        self.model.fit(embeddings, topics)
        
        return self
    
    def predict(
        self,
        embeddings: np.ndarray,
    ) -> pd.DataFrame:
        """Predict topics for document embeddings.
        
        Parameters
        ----------
        embeddings : np.ndarray
            Document embeddings with shape (n_documents, embedding_dim)
        
        Returns
        -------
        pd.DataFrame
            DataFrame with topic predictions and probabilities
        
        Raises
        ------
        ValueError
            If model has not been trained
        """
        if self.model is None or self.topic_names is None:
            raise ValueError("Model must be trained before prediction")
        
        # Get predictions and probabilities
        predictions = self.model.predict(embeddings)
        probabilities = self.model.predict_proba(embeddings)
        
        # Create result DataFrame
        result = pd.DataFrame({
            "primary_topic": predictions,
        })
        
        # Add probability for each topic
        for i, topic in enumerate(self.model.classes_):
            result[f"{topic}_probability"] = probabilities[:, i]
        
        # Add max probability
        result["topic_probability"] = np.max(probabilities, axis=1)
        
        # Replace predictions with "Unknown" if below threshold
        result.loc[result["topic_probability"] < self.threshold, "primary_topic"] = "Unknown"
        
        return result
    
    def evaluate(
        self,
        embeddings: np.ndarray,
        true_topics: Union[List[str], pd.Series],
    ) -> Dict[str, float]:
        """Evaluate the classifier on test data.
        
        Parameters
        ----------
        embeddings : np.ndarray
            Document embeddings with shape (n_documents, embedding_dim)
        true_topics : Union[List[str], pd.Series]
            True topic labels for each document
        
        Returns
        -------
        Dict[str, float]
            Dictionary with evaluation metrics
        
        Raises
        ------
        ValueError
            If model has not been trained
        """
        if self.model is None or self.topic_names is None:
            raise ValueError("Model must be trained before evaluation")
        
        # Convert pandas Series to list if needed
        if isinstance(true_topics, pd.Series):
            true_topics = true_topics.tolist()
        
        # Predict topics
        predictions = self.predict(embeddings)
        predicted_topics = predictions["primary_topic"].tolist()
        
        # Calculate metrics
        from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
        
        accuracy = accuracy_score(true_topics, predicted_topics)
        precision, recall, f1, _ = precision_recall_fscore_support(
            true_topics, predicted_topics, average="weighted"
        )
        
        # Return metrics
        return {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1": f1,
        }